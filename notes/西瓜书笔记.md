# 西瓜书笔记

[toc]



## 第一章 绪论

### 引言

### 基本术语

1. 数据集（Dataset）：样本的集合
2. 样本（Sample）：**每个对象都是一个样本**
3. 维度（Dimension）：**在二维数据表中，一个列可以看成一个维度。** ***维度是对特征的计数***
4. 特征（Feature）：特征是描述样本的属性或观察值。可以将特征视为样本在特征空间中的维度。例如，对于一张图像样本，其特征可以是像素的亮度值或颜色分布。选择合适的特征对于机器学习模型的性能至关重要。
5. 模型（Model）：模型是机器学习算法生成的表示数据关系的**函数或数学表达式**。模型通过从训练数据中学习，然后可以用于预测新样本的输出或进行其他任务。常见的机器学习模型包括线性回归、决策树、神经网络等。
6. 训练（Training）：
7. 测试（Testing）：
8. 算法（Algorithm）：
9. 评估函数（Evaluation Metric）：评估函数用于衡量机器学习模型的性能和准确度。它们可以根据任务的不同而变化，例如精度（Accuracy）、均方误差（Mean Squared Error）、召回率（Recall）、精确率（Precision）等。选择合适的评估函数可以帮助我们判断模型的优劣。

### 假设空间

> 指由一个算法或模型可以表示的所有可能解或函数的集合。假设空间定义了模型可以学习和表达的所有可能的假设。

### 归纳偏好

> 习算法对假设空间中的某些假设更有倾向性或偏好的一种倾向。它是算法设计者为了提高学习算法的效果而对模型、算法或搜索过程进行的一种设定。
>
> **奥卡姆剃刀**

NFL(No  Free Lunch Theorem) 定理最重要的寓意，是让我们清楚地认识到，脱离具体问题，空泛的谈论”什么学习算法更好“毫无意义，因为若考虑所有潜在的问题，则所有学习算法都一样好。

## 第二章 模型评估与选择

### 经验误差与过拟合

**经验误差/(训练误差)** : 与之相对应的是**泛化误差**(开放世界的模型误差)

**过拟合** : 模型在训练数据上表现良好，但在未见过的新数据上表现较差的现象，具体原因是因为模型的拟合效果过强，将数据集中的噪声也一并学习了 

### 评估方法

#### 留出法

##### 概念

> 将原始数据集分割成两个互斥的子集：训练集和测试集。

==需要注意的是，训练集和测试集的划分要尽可能的保持数据分布的一致性== 

##### 问题

> 1. 数据集的划分可能会对模型的评估结果产生一定的波动，因为不同的划分方式可能得到不同的评估结果。为了解决这个问题，一种常见的做法是执行多次随机划分，然后对评估结果进行平均。
> 2. 对于较小的数据集，使用留出法会导致训练样本的减少，可能会影响模型的性能。

#### 交叉验证法

##### 概念

> sd 
>
> ![img](http://image.zzzsleep.icu/v2-ff995d9c6b5be17ec55153ee78fd8a40_b.jpg)



#### 自助法

### 性能度量

### 比较检验

### 偏差与方差

## 第三章 线性模型

### 基本形式

### 线性回归

### 对数几率回归

### 线性判别分析

### 多分类学习

### 类别不平衡问题

## 第五章 神经网络

### 神经元模型

### 感知机与多层神经网络

### 误差逆传播算法

### 全局最小与局部极小

### 其他常见神经网络

### 深度学习

## 第六章 支持向量机

### 间隔与支持向量

### 对偶函数

### 核函数

### 软间隔与正则化

### 支持向量回归

### 核方法

## 第七章 贝叶斯分类器

### 贝叶斯决策论

### 极大似然估计

### 朴素贝叶斯分类器

### 半朴素贝叶斯分类器

### 贝叶斯网

### EM算法

## 第八章 集成学习

### 个体与集成

### Boosting

### Bagging与随机森林

### 结合策略

### 多样性

## 第九章 聚类

### 聚类任务

### 性能度量

### 距离计算

### 原型聚类

### 密度聚类

### 层次聚类

## 第十章 降维与度量学习

### k近邻学习

### 低维嵌入

### 主成分分析

### 核化线性降维

### 流形学习

### 度量学习

## 第十一章 特征选择与稀疏学习

## 第十二章 计算学习理论

## 第十三章 半监督学习

## 第十四章 概率图模型

## 第十六章 强化学习

